{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up your environment and build your first story from a text prompt"
      ],
      "metadata": {
        "id": "0baD8PXFh913"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLL3KqM3ht_1",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "%env GEMINI_API_KEY=AIzaSyAMG5M6jIypoSlGcdL0fkSK_NTI__DAY5k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers pillow google-generativeai"
      ],
      "metadata": {
        "id": "aGUyFcDhiGEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "client=genai.Client()"
      ],
      "metadata": {
        "id": "o7GHWSR2iIYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "  print(\"Please set you Gemini key in the environment variable GEMINI_API_KEY\")\n",
        "else:\n",
        "    client=genai.Client()\n",
        "    MODEL=\"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "meKsuYKViKus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=input(\"Enter your Story prompt and press enter:\\n\")\n",
        "if prompt.strip()==\"\":\n",
        "  print(\"No prompt entered , Exiting.\")\n",
        "else:\n",
        "  print(f\"Genetrating story for prompt: {prompt}\")\n",
        "  print(\"It may take few seconds\")\n",
        "  try:\n",
        "    resp=client.models.generate_content(model=MODEL,contents={prompt})\n",
        "    print(\"\\n----Generated Story----\\n\")\n",
        "    print(resp.text)\n",
        "  except Exception as e:\n",
        "    print(f\"Error occurred while generating story: {e}\")"
      ],
      "metadata": {
        "id": "CXJpGluXkx1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Turn a single image into a story using AI captioning"
      ],
      "metadata": {
        "id": "dW-Cpv5Fl4Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers pillow google-generativeai timm"
      ],
      "metadata": {
        "id": "stnm7nSpl8gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "from google import genai\n",
        "import os\n",
        "import io"
      ],
      "metadata": {
        "id": "HSh4ckrmmATL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "  print(\"Please set you Gemini key in the environment variable GEMINI_API_KEY\")\n",
        "else:\n",
        "    client=genai.Client()\n",
        "    MODEL=\"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "L9scx9i2mBEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")"
      ],
      "metadata": {
        "id": "PX7Hg7JjmEpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  image=Image.open(fn).convert('RGB')\n",
        "  display(image)"
      ],
      "metadata": {
        "id": "KrDSa59bmHBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=processor(images=image,return_tensors=\"pt\")\n",
        "out=model.generate(**inputs)\n",
        "\n",
        "caption=processor.decode(out[0],\n",
        "skip_special_tokens=True)\n",
        "\n",
        "print(\"Caption generated by BLIP: \")\n",
        "print(caption)"
      ],
      "metadata": {
        "id": "dHnua7Muowug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_prompt=(f\"Write a Short story(around 500-700 words) base on this scene description: {caption}\")\n",
        "print(story_prompt)\n",
        "\n",
        "print(\"Sending this to Gemini. \\n\" )\n",
        "\n",
        "response = client.models.generate_content(model=MODEL, contents=story_prompt)\n",
        "story=response.text\n",
        "print(\"\\n----Generated Story----\\n\")\n",
        "print(story)"
      ],
      "metadata": {
        "id": "K4WpolHOoxrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"generted_story.txt\",\"w\") as f:\n",
        "  f.write(story)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"generted_story.txt\")"
      ],
      "metadata": {
        "id": "6qQ1zjTCo1uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a multi-image narrative with sequencing and coherence"
      ],
      "metadata": {
        "id": "gPrB80-nqcjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ipywidgets"
      ],
      "metadata": {
        "id": "BmusVBjZqkI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "images=[]\n",
        "image_names=[]\n",
        "\n",
        "for name,file in uploaded.items():\n",
        "  image=Image.open(io.BytesIO(file)).convert('RGB')\n",
        "  image_names.append(name)\n",
        "  images.append(image)\n",
        "  display(image)"
      ],
      "metadata": {
        "id": "drsqzn-ZqpJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "blip_model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "\n",
        "captions=[]\n",
        "\n",
        "for img in images:\n",
        "  inputs=processor(images=img,return_tensors='pt')\n",
        "  out=blip_model.generate(**inputs,max_new_tokens=30)\n",
        "  caption=processor.decode(out[0],skip_special_tokens=True)\n",
        "  captions.append(caption)\n",
        "\n",
        "  print(\"Captions generated from images:\")\n",
        "  for i,caption in enumerate(captions):\n",
        "    print(f\"{image_names[i]}: {caption}\")"
      ],
      "metadata": {
        "id": "pWTivY2FqqCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display , clear_output\n",
        "\n",
        "tone_dropdown=widgets.Dropdown(\n",
        "    options=[\"whinsical\",\"adventurous\",\"suspenseful\",\"romantic\",\"Sci-fi\",\"mystery\"],\n",
        "    value=\"whinsical\",\n",
        "    description=\"Tone:\",\n",
        ")\n",
        "\n",
        "length_dropdown=widgets.Dropdown(\n",
        "    options=[\"Short(100-200 words)\",\n",
        "             \"Medium(300-400 words)\",\n",
        "             \"Long(500-700 words)\"],\n",
        "    value=\"Medium(300-400 words)\",\n",
        "    description=\"Length:\",\n",
        ")\n",
        "\n",
        "genetrate_button=widgets.Button(description=\"Generate Story\")\n",
        "output_box=widgets.Output()\n",
        "\n",
        "display(tone_dropdown,length_dropdown,genetrate_button,output_box)"
      ],
      "metadata": {
        "id": "KXgtP8LHqsCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def on_generate_button_clicked(b):\n",
        "  with output_box:\n",
        "    clear_output()\n",
        "\n",
        "    tone=tone_dropdown.value\n",
        "    length_map={\n",
        "        \"Short(100-200 words)\":\"100-200 words\",\n",
        "        \"Medium(300-400 words)\":\"300-400 words\",\n",
        "        \"Long(500-700 words)\":\"500-700 words\"\n",
        "    }\n",
        "    length=length_map[length_dropdown.value]\n",
        "\n",
        "    caption_prompt=\"\\n\".join([f\"-{c}\"for c in captions])\n",
        "\n",
        "    outline_prompt=(\n",
        "        f\"Using the following scene descriptions, create a 4-chapter story outline. \"\n",
        "            f\"Each chapter should have a title and a short summary.\\n\\n\"\n",
        "            f\"{caption_prompt}\\n\\nOutline\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        outline_response = client.models.generate_content(model=MODEL, contents=outline_prompt)\n",
        "        outline = outline_response.text\n",
        "        print(\"Story Outline:\\n\")\n",
        "        print(outline)\n",
        "\n",
        "        full_story = \"\"\n",
        "        for i in range(1, 5):\n",
        "          chapter_prompt = (\n",
        "              f\"Using the outline below, write Chapter {i} in a {tone} tone. \"\n",
        "              f\"Make it {length}. Add vivid details, good pacing, and consistent characters.\\n\\n\"\n",
        "              f\"{outline}\\n\\nChapter {i}\"\n",
        "          )\n",
        "\n",
        "          chapter_response = client.models.generate_content(model=MODEL, contents=chapter_prompt)\n",
        "          chapter_text = chapter_response.text\n",
        "          print(f\"\\n Chapter {i}:\\n\")\n",
        "          print(chapter_text)\n",
        "          full_story += f\"Chapter {i}:\\n{chapter_text}\\n\\n\"\n",
        "\n",
        "\n",
        "        with open(\"multi_image_story.txt\", \"w\") as f:\n",
        "            f.write(full_story)\n",
        "        print(\"\\n Story saved as multi_image_story.txt\")\n",
        "\n",
        "        from google.colab import files\n",
        "        files.download(\"multi_image_story.txt\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"Error generating story:\", e)\n",
        "\n",
        "genetrate_button.on_click(on_generate_button_clicked)"
      ],
      "metadata": {
        "id": "1UxYJuhaqvQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edit, Style and export stories with safety controls"
      ],
      "metadata": {
        "id": "-8n7wbq8tmzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gtts reportlab\n",
        "!pip install -q reportlab"
      ],
      "metadata": {
        "id": "MSLlydlntpVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_text =\"\"\"\n",
        "**Chapter 1: Whispers of Autumn's Past**\n",
        "\n",
        "*   **Summary:** Sunlight filters through the canopy of an autumn forest, illuminating a carpet of fallen leaves. Maya and Alex walk slowly, the crisp air doing little to lift Alex's quiet demeanor. Alex, once a promising soccer player, is lost in thought, a silent burden weighing on him. He occasionally glances at his phone, where a faded \"graphic of a soccer player running with a ball in his hand\" serves as a poignant reminder of a dream he once held tight, a dream that now feels distant. Maya senses his melancholic reflection, knowing the path ahead is as much about healing as it is about hiking.\n",
        "\n",
        "**Chapter 2: The Ascent of Uncertainty**\n",
        "\n",
        "*   **Summary:** The two friends begin their climb up a challenging mountain trail. The path is steep and winding, mirroring the emotional ascent Alex faces in coming to terms with his past. With every step, the majestic mountain peak looms larger in the background, a formidable symbol of the obstacles Alex believes stand between him and any future fulfillment. Maya, a steadfast companion, tries to engage him in conversation, gently nudging him to confront the disappointment of an injury that shattered his professional soccer ambitions, the very dream depicted in his memory.\n",
        "\n",
        "**Chapter 3: The Dream's Lingering Embrace**\n",
        "\n",
        "*   **Summary:** High on the trail, Alex pauses, momentarily lost in a vivid flashback or a powerful, almost dreamlike, vision. The \"graphic of a soccer player running with a ball in his hand\" comes alive in his mind – not a literal game scenario, but a symbolic image of his younger self, brimming with unadulterated passion, the soccer ball feeling like an extension of his very being. This raw, intimate connection to the sport, before the injury, surges through him, bringing both a pang of loss and a renewed sense of the profound joy the game once gifted him, intensifying his internal struggle amidst the arduous climb.\n",
        "\n",
        "**Chapter 4: The Open Field of New Beginnings**\n",
        "\n",
        "*   **Summary:** Finally, Alex and Maya break through the tree line, reaching a wide, \"grassy field with a mountain in the background.\" The view is breathtaking, expansive and serene. Standing on the vast, open space, with the imposing peak now behind them, Alex feels a profound shift. He realizes that while his professional dream may have ended, the spirit of the game and the joy it brings are not lost. This tranquil field, rather than a battleground, becomes a canvas for new possibilities, a place where he can embrace a different path – perhaps coaching, or simply rediscovering the simple love for the game – with the wisdom gained from his journey up the mountain, a journey shared and supported by Maya.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HW1gD649tses"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "\n",
        "def export_pdf(text, filename=\"story.pdf\"):\n",
        "  c = canvas.Canvas(filename, pagesize=letter)\n",
        "  width,height=letter\n",
        "  text_object=c.beginText(40,height-40)\n",
        "  text_object.setFont(\"Helvetica\",12)\n",
        "\n",
        "  for line in text.split(\"\\n\"):\n",
        "    for subline in[line[i:i+90] for i in range(0,len(line),90)]:\n",
        "      text_object.textLine(subline)\n",
        "  c.drawText(text_object)\n",
        "  c.showPage()\n",
        "  c.save()\n",
        "\n",
        "export_pdf(story_text)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"story.pdf\")"
      ],
      "metadata": {
        "id": "4PEU_if8t4sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from google.colab import files\n",
        "\n",
        "voices = {\n",
        "    \"Default English (US Female)\": {\"lang\": \"en\", \"tld\": \"com\"},\n",
        "    \"British Accent\": {\"lang\": \"en\", \"tld\": \"co.uk\"},\n",
        "    \"Australian Accent\": {\"lang\": \"en\", \"tld\": \"co.au\"},\n",
        "    \"Pakistani Accent\": {\"lang\": \"en\", \"tld\": \"co.pk\"},\n",
        "    \"Slow Reading Voice\": {\"lang\": \"es\", \"tld\": \"com\", \"slow\": True},\n",
        "}\n",
        "\n",
        "for label,option in voices.items():\n",
        "  print(f\"Generating Audio: {label}\")\n",
        "\n",
        "  tts=gTTS(\n",
        "      text=story_text,\n",
        "      lang=option[\"lang\"],\n",
        "      #tld=option.get(\"tld\",\"com\"), # Removed tld to use default\n",
        "      slow=option.get(\"slow\",False),\n",
        "\n",
        "  )\n",
        "\n",
        "  filename = f\"{label.replace(' ','_').lower()}.mp3\"\n",
        "\n",
        "  tts.save(filename)\n",
        "\n",
        "  display(Audio(filename=filename,autoplay=False))\n",
        "\n",
        "  files.download(filename)"
      ],
      "metadata": {
        "id": "3JvN3FYit-ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and showcase your AI StoryTeller app with Streamlit"
      ],
      "metadata": {
        "id": "cJb5ZuYv1ypU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_streamlit_story.py\n",
        "import streamlit as st #web app framework\n",
        "from PIL import Image\n",
        "import io, requests, os\n",
        "import textwrap\n",
        "from gtts import gTTS #translate text to speech\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.utils import ImageReader\n",
        "from pyngrok import ngrok\n",
        "import tempfile\n",
        "import google.generativeai as genai\n",
        "import torch\n",
        "\n",
        "#Authencation\n",
        "NGROK_AUTH_TOKEN = \"33T8ek51WYsEozKcynmWiITi3Er_89HiwrnWpjJqcEYGeTPPo\" # <--- Replace with your ngrok authtoken\n",
        "BACKGROUD_IMAGE_URL = \"https://i.postimg.cc/NF8HqzgR/web-back.avif\"\n",
        "GEMINI_API_KEY = \"AIzaSyAMG5M6jIypoSlGcdL0fkSK_NTI__DAY5k\"\n",
        "\n",
        "#SteamLit Page Setup/Style\n",
        "st.set_page_config(page_title=\"StoryTeller\",layout=\"wide\")\n",
        "\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "    .stApp {{\n",
        "        background-image: url(\"{BACKGROUD_IMAGE_URL}\");\n",
        "        background-size: cover;\n",
        "        background-attachment: fixed;\n",
        "    }}\n",
        "     selection[data-testid=\"stSidebar\"] {{\n",
        "        background: rgba (0,0,0,0.3);\n",
        "        backdrop-filter: blur(10px);\n",
        "        border-radius: 12px;\n",
        "        padding: 10px;\n",
        "   }}\n",
        "   div[data-testid=\"stFileUploader\"] {{\n",
        "        background: rgba (255,255,255,0.2);\n",
        "        border-radius: 10px;\n",
        "        padding: 10px;\n",
        "   }}\n",
        "   html, body, h1, h2, h3, h4, h5, h6, p, div, span, label, li, input, textarea {{\n",
        "      color: #93ABAC !important;\n",
        "   }}\n",
        "   .stButton>button, .stDownloadButton>button {{\n",
        "      color: #93ABAC !important;\n",
        "      border-color: #93ABAC;\n",
        "   }}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True,\n",
        ")\n",
        "\n",
        "st.title(\"Multi-Image AI StoryTeller\")\n",
        "st.markdown(\"Upload Images → Generate Story → Export as PDF and MP3\")\n",
        "\n",
        "with st.sidebar:\n",
        "  tone = st.selectbox(\"Tone\", [\"Wholesome\", \"Adventurous\", \"Suspenseful\", \"Romantic\", \"Sci-fi\", \"Mystery\"])\n",
        "  length_label = st.selectbox(\"Length\", [\"Short (200-300 words)\", \"Medium (300-600 words)\", \"Long (600-1000 words)\"])\n",
        "  strat_ngrok = st.checkbox(\"Start ngrok tunnel\")\n",
        "\n",
        "  if strat_ngrok:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    url = ngrok.connect(8501)\n",
        "    st.success(f\"Public URL: {url}\")\n",
        "\n",
        "uploaded_images = st.file_uploader(\"Upload multiple images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "\n",
        "#Caption model\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "  processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\") .to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  return processor, model\n",
        "\n",
        "processor, blip_model = load_models()\n",
        "\n",
        "#Config gemini\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "@st.cache_resource\n",
        "def load_gemini_model():\n",
        "  return genai.GenerativeModel(model_name=\"models/gemini-2.5-flash\")\n",
        "\n",
        "gemini_model = load_gemini_model()\n",
        "\n",
        "#Captioning the images\n",
        "def get_captions(images):\n",
        "  captions = []\n",
        "  for img in images:\n",
        "    if img.mode != \"RGB\":\n",
        "      img = img.convert(\"RGB\")\n",
        "    inputs = processor(images=img, return_tensors=\"pt\").to(blip_model.device)\n",
        "    out = blip_model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    captions.append(caption)\n",
        "  return captions\n",
        "\n",
        "\n",
        "def generate_story(captions, tone, length_label):\n",
        "  length_map = {\n",
        "      \"Short (200-300 words)\": (200, 300, 800),\n",
        "      \"Medium (300-600 words)\": (300, 600, 1200),\n",
        "      \"Long (600-1000 words)\": (600, 1000, 1600)\n",
        "  }\n",
        "  min_words, max_words, max_tokens = length_map.get(length_label, (300,600, 1200))\n",
        "\n",
        "  prompt = (\n",
        "      f\"you are a creative writer. Write a {tone.lower()} story based on the following image captions:\"\n",
        "      +\"\\n\".join([f\"- {cap}\" for cap in captions])\n",
        "      + f\"\\n\\nThe story should be vivid, engaging, and emotionally rich, with a coherent beginning\"\n",
        "      + f\"\\nMake it approximately between {min_words} and {max_words} word long.\"\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    response = gemini_model.generate_content(\n",
        "      contents=prompt,\n",
        "      generation_config=genai.GenerationConfig(\n",
        "          temperature=0.9,\n",
        "          top_p=0.95,\n",
        "          max_output_tokens=max_tokens,\n",
        "      )\n",
        "    )\n",
        "    return response.text.strip()\n",
        "  except Exception as e:\n",
        "    return f\"Error generating story: {e}\"\n",
        "\n",
        "\n",
        "#Pdf generation\n",
        "def create_pdf(story_text, images):\n",
        "  buffer = io.BytesIO()\n",
        "  c = canvas.Canvas(buffer, pagesize=A4)\n",
        "  w, h = A4\n",
        "\n",
        "  try:\n",
        "    bg_img = Image.open(requests.get(BACKGROUD_IMAGE_URL, stream=True).raw).convert(\"RGB\")\n",
        "    bg = ImageReader(bg_img)\n",
        "    c.drawImage(bg, 0, 0, width=w, height=h)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  c.setFont(\"Helvetica-Bold\", 16)\n",
        "  c.drawString(50, h - 50, \"Generated Story\")\n",
        "\n",
        "  text = textwrap.wrap(story_text, 100)\n",
        "  y = h - 80\n",
        "  for line in text:\n",
        "    if y < 80:\n",
        "      c.showPage()\n",
        "      y = h - 80\n",
        "    c.drawString(50, y, line)\n",
        "    y -= 15\n",
        "\n",
        "  if images:\n",
        "    c.showPage()\n",
        "    c.setFont(\"Helvetica-Bold\", 16)\n",
        "    c.drawString(50, h - 50, \"Uploaded Images\")\n",
        "    x, y = 50, h - 150\n",
        "    for img in images:\n",
        "      img_thumbnail = img.copy()\n",
        "      img_thumbnail.thumbnail((200, 200))\n",
        "      c.drawImage(ImageReader(img_thumbnail), x, y, width=img_thumbnail.width, height=img_thumbnail.height)\n",
        "      x += 220\n",
        "      if x > w - 200:\n",
        "        x = 50\n",
        "        y -= 220\n",
        "\n",
        "  c.save()\n",
        "  buffer.seek(0)\n",
        "  return buffer\n",
        "\n",
        "#Audio generation\n",
        "def create_audio(story):\n",
        "  audio_bytes = io.BytesIO()\n",
        "  tts = gTTS(story)\n",
        "  tts.write_to_fp(audio_bytes)\n",
        "  audio_bytes.seek(0)\n",
        "  return audio_bytes\n",
        "\n",
        "#Processing part\n",
        "if st.button(\"Generate Story\") and uploaded_images:\n",
        "  pil_images = [Image.open(img) for img in uploaded_images]\n",
        "  with st.spinner(\"Generating captions...\"):\n",
        "    captions = get_captions(pil_images)\n",
        "    for i, cap in enumerate(captions):\n",
        "      st.write(f\"**Image {i+1}**: {cap}\")\n",
        "\n",
        "  with st.spinner(\"Generating story...\"):\n",
        "    story = generate_story(captions, tone, length_label)\n",
        "    st.success(\"Story generated!\")\n",
        "    st.write(story)\n",
        "\n",
        "  with st.spinner(\"Creating PDF...\"):\n",
        "    pdf_file = create_pdf(story, pil_images)\n",
        "    st.download_button(\"Download PDF\", data=pdf_file, file_name=\"story.pdf\", mime=\"application/pdf\")\n",
        "\n",
        "  with st.spinner(\"Creating Audio...\"):\n",
        "    audio = create_audio(story)\n",
        "    st.audio(audio)\n",
        "    st.download_button(\"Download Audio as MP3\", data=audio, file_name=\"story.mp3\", mime=\"audio/mpeg\")\n",
        "\n",
        "elif not uploaded_images:\n",
        "  st.warning(\"Upload at least one image to begin.\")"
      ],
      "metadata": {
        "id": "1uTibCbU12Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "loQ2YRZqUZ66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a4f2498"
      },
      "source": [
        "!pip install -q streamlit pyngrok transformers torch gtts reportlab pillow\n",
        "\n",
        "!streamlit run app_streamlit_story.py --server.port 8501 &>/content/log.txt &\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"33T8ek51WYsEozKcynmWiITi3Er_89HiwrnWpjJqcEYGeTPPo\")\n",
        "url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
